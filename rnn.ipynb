{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "431f2d30",
   "metadata": {},
   "source": [
    "# Assignment 7 - RNNs and LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1389ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy\n",
    "import optparse\n",
    "\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import OrderedDict\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357d668",
   "metadata": {},
   "source": [
    "## Part A: Recurrent Neural Network & Classification\n",
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51e72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"/Users/parthbansal/Downloads/dev-access.csv\", engine='python', quotechar='|', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76034257",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c7cec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26773, 2)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e9e4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0]\n",
    "Y = dataset[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14e454ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(X):\n",
    "    reqJson = json.loads(item, object_pairs_hook=OrderedDict)\n",
    "    del reqJson['timestamp']\n",
    "    del reqJson['headers']\n",
    "    del reqJson['source']\n",
    "    del reqJson['route']\n",
    "    del reqJson['responsePayload']\n",
    "    X[index] = json.dumps(reqJson, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9423dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "num_words = len(tokenizer.word_index)+1\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95bec8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_log_length = 1024\n",
    "X_processed = pad_sequences(X, maxlen=max_log_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d72fbfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_processed, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2be80e",
   "metadata": {},
   "source": [
    "### Model 1 - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c31ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa98a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim=num_words, output_dim=32, input_length=max_log_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "689a7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(SimpleRNN(units=32, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "974de9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "944dc54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54ae0091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1024, 32)          2016      \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                2080      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,129\n",
      "Trainable params: 4,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2586542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = X_processed.astype('float32')\n",
    "Y = Y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e044d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 11:26:37.264164: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 20s 125ms/step - loss: 0.5339 - accuracy: 0.7180 - val_loss: 0.5609 - val_accuracy: 0.6536\n",
      "Epoch 2/3\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.3361 - accuracy: 0.8459 - val_loss: 0.1615 - val_accuracy: 0.9373\n",
      "Epoch 3/3\n",
      "157/157 [==============================] - 19s 122ms/step - loss: 0.1103 - accuracy: 0.9660 - val_loss: 0.0490 - val_accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_processed, Y, validation_split=0.25, epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b07488a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 4s 21ms/step - loss: 0.0577 - accuracy: 0.9854\n",
      "Test loss: 0.05769364908337593\n",
      "Test accuracy: 0.9853583574295044\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_processed, Y, batch_size=128)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376109c9",
   "metadata": {},
   "source": [
    "### Model 2 - LSTM + Dropout Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4b5d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=num_words, output_dim=32, input_length=max_log_length))\n",
    "model2.add(LSTM(units=64, recurrent_dropout=0.5))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a84bed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "377c615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1024, 32)          2016      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,913\n",
      "Trainable params: 26,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd8447f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "157/157 [==============================] - 165s 1s/step - loss: 0.4124 - accuracy: 0.8123 - val_loss: 0.1352 - val_accuracy: 0.9589\n",
      "Epoch 2/3\n",
      "157/157 [==============================] - 167s 1s/step - loss: 0.1131 - accuracy: 0.9713 - val_loss: 0.1716 - val_accuracy: 0.9550\n",
      "Epoch 3/3\n",
      "157/157 [==============================] - 165s 1s/step - loss: 0.1028 - accuracy: 0.9771 - val_loss: 0.0918 - val_accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_processed, Y, validation_split=0.25, epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4011a224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 33s 155ms/step - loss: 0.0807 - accuracy: 0.9808\n",
      "Test loss: 0.08070356398820877, Test accuracy: 0.9808015823364258\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model2.evaluate(X_processed, Y, batch_size=128)\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7edffba",
   "metadata": {},
   "source": [
    "### Recurrent Neural Net Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7516c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=num_words, output_dim=64, input_length=max_log_length))\n",
    "\n",
    "model.add(LSTM(units=64, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(LSTM(units=32, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(LSTM(units=16, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.add(Dropout(rate=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a5d9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a11a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 1024, 64)          4032      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1024, 64)          33024     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 1024, 32)          12416     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,625\n",
      "Trainable params: 52,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9da2d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "157/157 [==============================] - 503s 3s/step - loss: 2.4805 - accuracy: 0.7171 - val_loss: 0.3316 - val_accuracy: 0.9184\n",
      "Epoch 2/3\n",
      "157/157 [==============================] - 563s 4s/step - loss: 2.3452 - accuracy: 0.8221 - val_loss: 0.2576 - val_accuracy: 0.9725\n",
      "Epoch 3/3\n",
      "157/157 [==============================] - 568s 4s/step - loss: 2.2789 - accuracy: 0.8348 - val_loss: 0.2417 - val_accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_processed, Y, validation_split=0.25, epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d770767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 72s 342ms/step - loss: 0.2122 - accuracy: 0.9821\n",
      "Test Loss: 0.21218332648277283\n",
      "Test Accuracy: 0.9821462035179138\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_processed, Y, batch_size=128)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750d589",
   "metadata": {},
   "source": [
    "### Conceptual Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc410c",
   "metadata": {},
   "source": [
    "\n",
    "**Explain the difference between the relu activation function and the sigmoid activation function.**\n",
    "- The relu (rectified linear unit) activation function outputs 0 for any input less than 0 and the input value for any input greater than or equal to 0, while the sigmoid activation function maps any input to a value between 0 and 1, with outputs closer to 0 indicating negative inputs and outputs closer to 1 indicating positive inputs.\n",
    "\n",
    "**Describe what one epoch actually is (epoch was a parameter used in the .fit() method).**\n",
    "- One epoch is a single pass through the entire training dataset during training. In other words, the model is shown every training example once during an epoch, and the model weights are updated based on the errors generated by the predictions.\n",
    "\n",
    "**Explain how dropout works (you can look at the keras code and/or documentation) for (a) training, and (b) test data sets.**\n",
    "- Dropout is a regularization technique for neural networks that randomly drops out (sets to zero) a proportion of the neuron outputs during training. During training, dropout works by randomly dropping out neurons with a certain probability so that other neurons have to take over the representation. During testing, dropout is not applied and the model uses all the neurons. Dropout can help to prevent overfitting.\n",
    "\n",
    "**Explain why problems such as this homework assignment are better modeled with RNNs than CNNs. What type of problem will CNNs outperform RNNs on?**\n",
    "- RNNs are better suited for modeling sequential data, such as natural language processing or time-series data, where the order of input data is important. CNNs are better suited for problems that involve spatial relationships between inputs, such as image or audio classification.\n",
    "\n",
    "**Explain what RNN problem is solved using LSTM and briefly describe how.**\n",
    "- The vanishing gradient problem can occur when training RNNs with traditional gradient descent, where the gradients become very small and the model stops learning. LSTM (Long Short-Term Memory) is a type of RNN that solves this problem by using a gating mechanism to control the flow of information through the network. LSTMs can selectively forget or remember previous inputs, allowing them to learn long-term dependencies in the input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ca96a",
   "metadata": {},
   "source": [
    "## Part B: Time Series with LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87940091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def create_data_for_NN(\n",
    "    data: pd.DataFrame, Y_var: str, lag: int, test_ratio: float\n",
    ") -> Tuple[np.array, np.array, np.array, np.array]:\n",
    "    \"\"\"Function to return lagged time series data after train-test split\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Raw time series data frame\n",
    "        Y_var (str): String with the name of y variable\n",
    "        lag (int): number of lagged records to consider\n",
    "        test_ratio (float): ratio of data to consider for test set\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.array, np.array, np.array, np.array]: Lagged and split numpy arrays\n",
    "    \"\"\"\n",
    "    y = data[Y_var].tolist()\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    if len(y) - lag <= 0:\n",
    "        X.append(y)\n",
    "    else:\n",
    "        for i in range(len(y) - lag):\n",
    "            Y.append(y[i + lag])\n",
    "            X.append(y[i : (i + lag)])\n",
    "\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "    # Reshaping the X array to an LSTM input shape\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Creating training and test sets\n",
    "    X_train = X\n",
    "    X_test = []\n",
    "\n",
    "    Y_train = Y\n",
    "    Y_test = []\n",
    "\n",
    "    if test_ratio > 0:\n",
    "        index = round(len(X) * test_ratio)\n",
    "        X_train = X[: (len(X) - index)]\n",
    "        X_test = X[-index:]\n",
    "\n",
    "        Y_train = Y[: (len(X) - index)]\n",
    "        Y_test = Y[-index:]\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "lag = 3\n",
    "test_ratio = 0.15\n",
    "\n",
    "data = pd.read_csv('/Users/parthbansal/Downloads/DAYTON_hourly-2.csv', parse_dates=['Datetime'])\n",
    "data.Datetime = pd.to_datetime(data.Datetime)\n",
    "data.sort_values(by=\"Datetime\", inplace=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = create_data_for_NN(\n",
    "    data, data.columns[-1], lag, test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b138a1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 12:27:15.941507: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2577/2577 [==============================] - 3s 1ms/step - loss: 4256113.5000 - val_loss: 3773061.5000\n",
      "Epoch 2/20\n",
      "2577/2577 [==============================] - 3s 1ms/step - loss: 4014283.5000 - val_loss: 3542239.5000\n",
      "Epoch 3/20\n",
      "2577/2577 [==============================] - 3s 997us/step - loss: 3774168.7500 - val_loss: 3317240.0000\n",
      "Epoch 4/20\n",
      "2577/2577 [==============================] - 3s 1ms/step - loss: 3542790.0000 - val_loss: 3100479.2500\n",
      "Epoch 5/20\n",
      "2577/2577 [==============================] - 3s 1ms/step - loss: 3319341.0000 - val_loss: 2891507.5000\n",
      "Epoch 6/20\n",
      "2577/2577 [==============================] - 3s 993us/step - loss: 3103776.5000 - val_loss: 2690390.7500\n",
      "Epoch 7/20\n",
      "2577/2577 [==============================] - 3s 985us/step - loss: 2895819.5000 - val_loss: 2496846.7500\n",
      "Epoch 8/20\n",
      "2577/2577 [==============================] - 3s 989us/step - loss: 2695633.5000 - val_loss: 2311106.2500\n",
      "Epoch 9/20\n",
      "2577/2577 [==============================] - 3s 979us/step - loss: 2503118.5000 - val_loss: 2132998.0000\n",
      "Epoch 10/20\n",
      "2577/2577 [==============================] - 3s 978us/step - loss: 2318415.7500 - val_loss: 1962730.3750\n",
      "Epoch 11/20\n",
      "2577/2577 [==============================] - 3s 1ms/step - loss: 2141358.5000 - val_loss: 1800019.8750\n",
      "Epoch 12/20\n",
      "2577/2577 [==============================] - 3s 996us/step - loss: 1972094.5000 - val_loss: 1645166.0000\n",
      "Epoch 13/20\n",
      "2577/2577 [==============================] - 3s 993us/step - loss: 1810425.2500 - val_loss: 1497839.3750\n",
      "Epoch 14/20\n",
      "2577/2577 [==============================] - 3s 1ms/step - loss: 1656618.0000 - val_loss: 1358424.7500\n",
      "Epoch 15/20\n",
      "2577/2577 [==============================] - 3s 1ms/step - loss: 1510395.6250 - val_loss: 1226513.8750\n",
      "Epoch 16/20\n",
      "2577/2577 [==============================] - 3s 1ms/step - loss: 1371820.2500 - val_loss: 1102252.8750\n",
      "Epoch 17/20\n",
      "2577/2577 [==============================] - 3s 994us/step - loss: 1240994.8750 - val_loss: 985746.3750\n",
      "Epoch 18/20\n",
      "2577/2577 [==============================] - 3s 994us/step - loss: 1117832.2500 - val_loss: 876835.1250\n",
      "Epoch 19/20\n",
      "2577/2577 [==============================] - 3s 993us/step - loss: 1002281.8125 - val_loss: 775494.4375\n",
      "Epoch 20/20\n",
      "2577/2577 [==============================] - 3s 996us/step - loss: 894288.1875 - val_loss: 681773.6875\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(units=64, input_shape=(3, 1)),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "model1.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "history1 = model1.fit(X_train, Y_train, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29abb782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 4185324.7500 - val_loss: 4095179.5000\n",
      "Epoch 2/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 4034386.2500 - val_loss: 3947911.0000\n",
      "Epoch 3/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 3888727.2500 - val_loss: 3803988.5000\n",
      "Epoch 4/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 3746085.7500 - val_loss: 3662906.0000\n",
      "Epoch 5/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 3606296.2500 - val_loss: 3524655.5000\n",
      "Epoch 6/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 3465920.5000 - val_loss: 3381264.5000\n",
      "Epoch 7/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 3323617.5000 - val_loss: 3241748.5000\n",
      "Epoch 8/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 3185608.5000 - val_loss: 3105484.2500\n",
      "Epoch 9/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 3050843.2500 - val_loss: 2972446.7500\n",
      "Epoch 10/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 2919096.5000 - val_loss: 2842393.5000\n",
      "Epoch 11/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 2790528.5000 - val_loss: 2715528.7500\n",
      "Epoch 12/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 2665054.5000 - val_loss: 2591778.5000\n",
      "Epoch 13/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 2542615.0000 - val_loss: 2470998.0000\n",
      "Epoch 14/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 2423303.5000 - val_loss: 2353403.5000\n",
      "Epoch 15/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 2307065.2500 - val_loss: 2238873.2500\n",
      "Epoch 16/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 2193950.7500 - val_loss: 2127448.7500\n",
      "Epoch 17/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 2083907.6250 - val_loss: 2019099.5000\n",
      "Epoch 18/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 1976932.8750 - val_loss: 1913826.7500\n",
      "Epoch 19/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 1873069.8750 - val_loss: 1811660.6250\n",
      "Epoch 20/20\n",
      "2578/2578 [==============================] - 12s 5ms/step - loss: 1772258.0000 - val_loss: 1712583.5000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = create_data_for_NN(\n",
    "    data, data.columns[-1], lag=24, test_ratio=test_ratio)\n",
    "\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(units=64, input_shape=(24, 1)),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "model2.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "history2 = model2.fit(X_train, Y_train, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e2cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2578/2578 [==============================] - 14s 5ms/step - loss: 4075266.0000 - val_loss: 3882451.2500\n",
      "Epoch 2/10\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 3723233.5000 - val_loss: 3541321.7500\n",
      "Epoch 3/10\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 3390821.5000 - val_loss: 3217834.7500\n",
      "Epoch 4/10\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 3075198.0000 - val_loss: 2910892.5000\n",
      "Epoch 5/10\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 2776007.0000 - val_loss: 2620266.7500\n",
      "Epoch 6/10\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 2493376.7500 - val_loss: 2346349.0000\n",
      "Epoch 7/10\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 2227392.7500 - val_loss: 2088893.8750\n",
      "Epoch 8/10\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 1977812.8750 - val_loss: 1847903.0000\n",
      "Epoch 9/10\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 1744604.8750 - val_loss: 1623173.8750\n",
      "Epoch 10/10\n",
      "2578/2578 [==============================] - 13s 5ms/step - loss: 1527706.8750 - val_loss: 1414823.7500\n"
     ]
    }
   ],
   "source": [
    "model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64), input_shape=(24, 1)),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "model3.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "history3 = model3.fit(X_train, Y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_test)\n",
    "rmse1 = np.sqrt(np.mean((Y_test - y_pred1)**2))\n",
    "print(\"RMSE (model1):\", rmse1)\n",
    "\n",
    "y_pred2 = model2.predict(X_test)\n",
    "rmse2 = np.sqrt(np.mean((Y_test - y_pred2)**2))\n",
    "print(\"RMSE (model2):\", rmse2)\n",
    "\n",
    "y_pred3 = model3.predict(X_test)\n",
    "rmse3 = np.sqrt(np.mean((Y_test - y_pred3)**2))\n",
    "print(\"RMSE (model3):\", rmse3)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea8890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
